<div align="center">
  <h1><img src="https://img.shields.io/badge/Streamlit-%2300FFFF.svg?style=for-the-badge&logo=streamlit&logoColor=black" alt="Streamlit"> + <img src="https://img.shields.io/badge/Embedchain-%233874c8.svg?style=for-the-badge&logoColor=white" alt="Embedchain"> = 💬 Chat with Your Docs!</h1>
  <p>🚀 Exploring cutting-edge tools to enhance document interaction. Currently showcasing a blend of Streamlit's sleek frontend and Embedchain's robust backend.</p>
</div>

---

## ✨ **Llama 3.2 Powered Document Chat (Streamlit + Embedchain)** ✨

Dive into a world where you can have insightful conversations with your local documents! This application is a testament to the ongoing exploration of innovative technologies for document interaction. We've harnessed the user-friendly power of **Streamlit** for the frontend and the intelligent document processing capabilities of **Embedchain** for the backend. Experience seamless chatting with your PDF, text, and markdown files, all powered by the locally run **Llama 3.2** language model via **Ollama**.

Unleash the potential of your documents by uploading them, integrating them into an Embedchain-managed knowledge base, and posing questions that delve into their very essence. Embedchain expertly handles the creation of document embeddings, their storage, and the retrieval of relevant information. This retrieved context then fuels the locally hosted Llama 3.2 model to generate informed and pertinent answers, all within the fluid and interactive Streamlit interface. From effortless document preview to intuitive management, this application aims to redefine how you interact with your digital knowledge.

## 💡 **How It Works**

1.  **📤 Document Upload:** Effortlessly upload your PDF, text, or markdown files through the intuitive Streamlit sidebar.
2.  **🧠 Knowledge Base Integration:** Upon clicking "Add to Knowledge Base," Embedchain springs into action, processing your file content, generating semantic embeddings, and storing them within a local Chroma vector database. Each document is uniquely identified and its key details (filename, type, etc.) are meticulously tracked.
3.  **🗣️ Chat Interface:** Navigate to the "Chat Interface" tab, where a clean Streamlit chat window awaits your queries.
4.  **❓ Intelligent Question Answering:** When you pose a question, Embedchain orchestrates the following:
    * Embedding your query using the same sophisticated model (Llama 3.2 via Ollama).
    * Conducting a semantic search within the Chroma vector database to pinpoint the most relevant document segments based on embedding similarity.
    * Dispatching these pertinent document snippets along with your question to the locally running Llama 3.2 model.
    * Receiving a contextually rich answer generated by Llama 3.2, deeply informed by your documents.
5.  **📂 Document Management:** The "Document Management" tab, elegantly crafted with Streamlit components, presents a clear overview of all documents currently residing in your Embedchain-powered knowledge base. Here, you have the power to delete individual documents or perform a comprehensive clearing of the entire knowledge repository.
6.  **👓 Document Preview:** Before committing a file to the knowledge base, Streamlit provides an immediate preview of its contents directly in the sidebar. For text and markdown files, a dedicated Streamlit button allows you to leverage the local LLM for insightful summarization or in-depth analysis of the entire content.
7.  **📜 Chat History:** Streamlit's session state management diligently maintains the thread of your conversation within the current session, ensuring a coherent context for all subsequent interactions.

## 🎯 **Use Cases**

Unlock a multitude of possibilities with this Streamlit and Embedchain powered application:

* **🔬 Research Powerhouse:** Instantly extract key findings and deep insights from research papers, comprehensive reports, and insightful articles.
* **📄 Effortless Document Analysis:** Grasp the core essence of extensive documents without the need for exhaustive reading.
* **📝 Enhanced Note Review:** Engage in dynamic conversations with your personal notes and markdown files to effortlessly recall specific details.
* **📚 Interactive Learning:** Pose direct questions about your study materials, textbooks, and a wide array of educational resources.
* **🔒 Local Knowledge Hub:** Establish a secure and private knowledge base for your sensitive files.

## 🛠️ **Installation Guide**

Follow these straightforward steps to get the application up and running on your local machine:

### ✅ **Prerequisites**

1.  **🐍 Python 3.8+:** Ensure you have Python installed. Verify your version by running `python --version` or `python3 --version` in your terminal.
2.  **🦉 Ollama:** This application relies on Ollama to locally host the Llama 3.2 language model. Install it from the [official Ollama website](https://ollama.com/).
3.  **🦙 Llama 3.2 Model:** After installing Ollama, download the Llama 3.2 model by executing the following command in your terminal:
    ```bash
    ollama pull llama3.2:latest
    ```

### ⚙️ **Installation Steps**

1.  **💾 Clone Repository (Optional):** If the code is hosted on GitHub:
    ```bash
    git clone <repository_url>
    cd <repository_directory>
    ```
2.  **📦 Install Dependencies:** Navigate to the directory containing the Python code and install the necessary libraries using pip:
    ```bash
    pip install streamlit embedchain streamlit-chat python-dotenv
    ```

### ▶️ **Running the Application**

1.  **💾 Save the Code:** Ensure the provided Python code is saved as a `.py` file (e.g., `app.py`).
2.  **🚀 Run Streamlit:** Open your terminal in the directory where you saved `app.py` and execute:
    ```bash
    streamlit run app.py
    ```
    The application will automatically launch in your default web browser.

## 📜 **Requirements and Dependencies**

* **Python:** Version 3.8 or higher
* **Ollama:** Installed and actively running with the `llama3.2:latest` model downloaded.
* **Python Libraries:**
    * `streamlit`
    * `embedchain`
    * `streamlit-chat`
    * `python-dotenv` (optional, but recommended for managing environment variables)

**Important:** Ensure that Ollama is running in the background for the Streamlit application to successfully connect to the Llama 3.2 model. If you encounter any issues, please verify that Ollama is running and that the `llama3.2:latest` model has been correctly pulled.

---

<div align="center">
  <p>Made with ❤️ and a dash of curiosity!</p>
</div>
